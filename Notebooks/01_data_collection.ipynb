{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcd1d37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching last 200 videos...\n",
      "Collected 50 videos...\n",
      "Collected 100 videos...\n",
      "Collected 150 videos...\n",
      "Collected 200 videos...\n",
      "SUCCESS: Saved 200 rows to ..\\data\\raw\\h3_podcast_raw.csv\n",
      "      video_id                                              title  \\\n",
      "0  1ANasCrCylQ                 Ethan Gets DESTROYED By Lena's Mom   \n",
      "1  od9xGNG_MdI  James Charles is a disgusting creep that needs...   \n",
      "2  sszRW65FtR8   Where one of the most classic soundbites started   \n",
      "3  ecYEhD_9szQ             Hasan Is Not Doing Well - H3 Show #217   \n",
      "4  WSY166nkVGs                      Ethan Talks About His Anxiety   \n",
      "\n",
      "           published_at  view_count  like_count  comment_count  \\\n",
      "0  2025-12-06T20:05:46Z       89607        3571            169   \n",
      "1  2025-12-06T01:13:15Z      410014        9365           1123   \n",
      "2  2025-12-05T18:43:17Z       28858        1384             65   \n",
      "3  2025-12-05T00:01:47Z      371138        8584           1081   \n",
      "4  2025-12-04T23:19:27Z       77527        3694            237   \n",
      "\n",
      "                                         description  \n",
      "0  TEDDY FRESH...http://teddyfresh.com\\n\\nFollow ...  \n",
      "1  Thank you to andSons Chocolatiers for sponsori...  \n",
      "2  TEDDY FRESH...http://teddyfresh.com\\n\\nFollow ...  \n",
      "3  TEDDY FRESH...http://teddyfresh.com\\nLearn mor...  \n",
      "4  TEDDY FRESH...http://teddyfresh.com\\n\\nFollow ...  \n"
     ]
    }
   ],
   "source": [
    "import googleapiclient.discovery\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "API_KEY = \"AIzaSyCX5UpOadouhvTa9MDHAfnC9fFksf1HsXA\"  \n",
    "CHANNEL_ID = \"UCLtREJY21xRfCuEKvdki1Kw\" # H3 Podcast Channel\n",
    "MAX_VIDEOS = 200 \n",
    "\n",
    "def get_h3_dataset(api_key, channel_id, max_results):\n",
    "    youtube = googleapiclient.discovery.build(\"youtube\", \"v3\", developerKey=api_key)\n",
    "    \n",
    "    video_data = []\n",
    "    uploads_playlist_id = \"UU\" + channel_id[2:] \n",
    "    next_page_token = None\n",
    "    \n",
    "    print(f\"Fetching last {max_results} videos...\")\n",
    "\n",
    "    while len(video_data) < max_results:\n",
    "        try:\n",
    "            request = youtube.playlistItems().list(\n",
    "                part=\"snippet,contentDetails\",\n",
    "                playlistId=uploads_playlist_id,\n",
    "                maxResults=50,\n",
    "                pageToken=next_page_token\n",
    "            )\n",
    "            response = request.execute()\n",
    "\n",
    "            vid_ids = [item['contentDetails']['videoId'] for item in response['items']]\n",
    "            \n",
    "            stats_request = youtube.videos().list(\n",
    "                part=\"statistics,snippet\",\n",
    "                id=','.join(vid_ids)\n",
    "            )\n",
    "            stats_response = stats_request.execute()\n",
    "\n",
    "            for item in stats_response['items']:\n",
    "                stats = item['statistics']\n",
    "                snippet = item['snippet']\n",
    "                \n",
    "                video_data.append({\n",
    "                    \"video_id\": item['id'],\n",
    "                    \"title\": snippet['title'],\n",
    "                    \"published_at\": snippet['publishedAt'],\n",
    "                    \"view_count\": int(stats.get('viewCount', 0)),\n",
    "                    \"like_count\": int(stats.get('likeCount', 0)),\n",
    "                    \"comment_count\": int(stats.get('commentCount', 0)),\n",
    "                    \"description\": snippet['description'] \n",
    "                })\n",
    "\n",
    "            next_page_token = response.get('nextPageToken')\n",
    "            if not next_page_token:\n",
    "                break \n",
    "                \n",
    "            print(f\"Collected {len(video_data)} videos...\")\n",
    "            time.sleep(0.5) \n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            break\n",
    "\n",
    "    return pd.DataFrame(video_data)\n",
    "\n",
    "# --- EXECUTE ---\n",
    "df = get_h3_dataset(API_KEY, CHANNEL_ID, MAX_VIDEOS)\n",
    "\n",
    "# Save to the 'data/raw' folder you created\n",
    "save_path = os.path.join(\"..\", \"data\", \"raw\", \"h3_podcast_raw.csv\")\n",
    "# Note: \"..\" moves up one level from 'notebooks' to the root, then into 'data/raw'\n",
    "\n",
    "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "df.to_csv(save_path, index=False)\n",
    "\n",
    "print(f\"SUCCESS: Saved {len(df)} rows to {save_path}\")\n",
    "print(df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
